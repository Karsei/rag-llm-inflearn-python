# streamlit run chat.py

import os
import chromadb
from dotenv import load_dotenv
from dataclasses import dataclass
from langchain_chroma import Chroma
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_community.document_loaders import Docx2txtLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
import streamlit as st

@dataclass(frozen=True)
class Constants:
    TAX_WITH_MARKDOWN_PATH = "./tax_with_markdown.docx" # ì œì¼ ì í•©
    CHROMA_DB_PATH = "./chroma"
    CHROMA_COLLECTION_NAME = "chroma-tax"
    MODEL_CHATGPT = "gpt-4o-mini"
    MODEL_EMBEDDING = "text-embedding-3-large"

load_dotenv()

# streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì†Œë“ì„¸ ì±—ë´‡",
    page_icon="ğŸ¤–"
)
st.title("ğŸ¤– ì†Œë“ì„¸ ì±—ë´‡")
st.caption("ì†Œë“ì„¸ì— ê´€ë ¨ëœ ëª¨ë“  ê²ƒì„ ë‹µí•´ë“œë¦½ë‹ˆë‹¤!")

# ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë©”ì„¸ì§€ë“¤ì„ ê¸°ì–µí•´ì•¼ í•œë‹¤.
if 'message_list' not in st.session_state:
    st.session_state.message_list = []

# ì´ì „ì— ì…ë ¥í•œ ë©”ì„¸ì§€ë“¤ì´ í‘œì‹œë˜ì–´ì•¼ í•œë‹¤.
print(f"before == {st.session_state.message_list}")
for message in st.session_state.message_list:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# AI ë¡œë¶€í„° ë‹µë³€ì„ ê°€ì ¸ì˜¨ë‹¤.
def get_ai_message(user_message):
    # ë¬¸ì„œë¥¼ ìª¼ê° ë‹¤.
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1500,  # ë‚´ë¶€ ë¬¸ì„œ ê°ì²´ í•˜ë‚˜ê°€ ê°€ì§ˆ ìˆ˜ ìˆëŠ” í† í° ìˆ˜
        chunk_overlap=200  # ìœ„/ì•„ë˜ ë¬¸ë§¥ì„ ê²¹ì¹˜ê²Œ í•˜ì—¬ ë¬¸ì„œ ê°ì²´ ì‚¬ì´ì˜ ê²¹ì¹˜ëŠ” í† í°ì˜ ì •ë„ (ìœ ì‚¬ë„ë¥¼ ìœ„í•´)
    )

    loader = Docx2txtLoader(Constants.TAX_WITH_MARKDOWN_PATH)
    document = loader.load_and_split(text_splitter=text_splitter)
    embedding = OpenAIEmbeddings(model=Constants.MODEL_EMBEDDING)

    exist_db = False
    if os.path.isdir(Constants.CHROMA_DB_PATH):
        exist_db = True

    if exist_db:
        database = Chroma(
            collection_name=Constants.CHROMA_COLLECTION_NAME,
            persist_directory=Constants.CHROMA_DB_PATH,
            embedding_function=embedding
        )
    else:
        chromadb.api.client.SharedSystemClient.clear_system_cache()
        database = Chroma.from_documents(
            documents=document,
            embedding=embedding,
            collection_name=Constants.CHROMA_COLLECTION_NAME,  # RDBë¡œ ì¹˜ë©´ í…Œì´ë¸” ì´ë¦„
            persist_directory=Constants.CHROMA_DB_PATH  # ë°ì´í„° ì €ì¥ ìœ„ì¹˜
        )

    retriever = database.as_retriever(search_kwargs={'k': 4})
    retrieved_docs = retriever.invoke(user_message)

    llm = ChatOpenAI(model=Constants.MODEL_CHATGPT)

    dictionary = ["ì‚¬ëŒì„ ë‚˜íƒ€ë‚´ëŠ” í‘œí˜„ -> ê±°ì£¼ì"]
    prompt = ChatPromptTemplate.from_template(f"""
        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³´ê³ , ìš°ë¦¬ì˜ ì‚¬ì „ì„ ì°¸ê³ í•´ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³€ê²½í•´ì£¼ì„¸ìš”.
        ë§Œì•½ ë³€ê²½í•  í•„ìš”ê°€ ì—†ë‹¤ê³  íŒë‹¨ë˜ë©´, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³€ê²½í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.
        ê·¸ëŸ° ê²½ìš°ì—ëŠ” ì§ˆë¬¸ë§Œ ë¦¬í„´í•´ì£¼ì„¸ìš”
        ì‚¬ì „: {dictionary}

        ì§ˆë¬¸: {{query}}
    """)
    dictionary_chain = prompt | llm | StrOutputParser()

    template = """[Identity]
    - ë‹¹ì‹ ì€ ìµœê³ ì˜ í•œêµ­ ì†Œë“ì„¸ ì „ë¬¸ê°€ ì…ë‹ˆë‹¤.
    - [Context]ë¥¼ ì°¸ê³ í•´ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

    [Context]
    {retrieved_docs}

    Question: {query}
    """
    rag_template = PromptTemplate(
        template=template,
        input_variables=['retrieved_docs', 'query'])
    rag_chain = rag_template | llm  # LCEL
    tax_chain = {"query": dictionary_chain, "retrieved_docs": lambda x: retrieved_docs} | rag_chain

    ai_response = tax_chain.invoke({'retrieved_docs': retrieved_docs, "query": user_message})
    print(ai_response)
    return ai_response.content

if user_question := st.chat_input(placeholder="ì†Œë“ì„¸ì— ê´€ë ¨ëœ ê¶ê¸ˆí•œ ë‚´ìš©ë“¤ì„ ë§ì”€í•´ì£¼ì„¸ìš”!"):
    # pass
    with st.chat_message("user"):
        st.write(user_question)
    st.session_state.message_list.append({"role": "user", "content": user_question})

    with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤"):
        ai_message = get_ai_message(user_question)
        with st.chat_message("ai"):
            st.write(ai_message)
        st.session_state.message_list.append({"role": "ai", "content": ai_message})
print(f"after == {st.session_state.message_list}")